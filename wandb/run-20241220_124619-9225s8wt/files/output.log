12/20/2024 12:46:22 - INFO - __main__ - ***** Running training *****
12/20/2024 12:46:22 - INFO - __main__ -   Num examples = 1566
12/20/2024 12:46:22 - INFO - __main__ -   Num Epochs = 100
12/20/2024 12:46:22 - INFO - __main__ -   Instantaneous batch size per device = 64
12/20/2024 12:46:22 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 64
12/20/2024 12:46:22 - INFO - __main__ -   Gradient Accumulation steps = 1
12/20/2024 12:46:22 - INFO - __main__ -   Total optimization steps = 2500
  1%|█▌                                                                                                                                                       | 25/2500 [00:07<09:34,  4.31it/s]/home/agrosavia/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
64
128
192
256
277
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Configuration saved in ./cocoa_outputs_efficientnet/config.json
Model weights saved in ./cocoa_outputs_efficientnet/model.safetensors
Image processor saved in ./cocoa_outputs_efficientnet/preprocessor_config.json
model.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16.3M/16.3M [00:01<00:00, 13.4MB/s]
  1%|█▉                                                                                                                                                       | 32/2500 [00:14<17:27,  2.36it/s]Traceback (most recent call last):
  File "/home/agrosavia/cacao-hf/main.py", line 920, in <module>
    main()
  File "/home/agrosavia/cacao-hf/main.py", line 740, in main
    for step, batch in enumerate(active_dataloader):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/agrosavia/anaconda3/lib/python3.12/site-packages/accelerate/data_loader.py", line 563, in __iter__
    next_batch = next(dataloader_iter)
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/agrosavia/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/agrosavia/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 673, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/agrosavia/anaconda3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 50, in fetch
    data = self.dataset.__getitems__(possibly_batched_index)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/agrosavia/anaconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py", line 2784, in __getitems__
    batch = self.__getitem__(keys)
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/agrosavia/anaconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py", line 2780, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/agrosavia/anaconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py", line 2765, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/agrosavia/anaconda3/lib/python3.12/site-packages/datasets/formatting/formatting.py", line 639, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/agrosavia/anaconda3/lib/python3.12/site-packages/datasets/formatting/formatting.py", line 407, in __call__
    return self.format_batch(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/agrosavia/anaconda3/lib/python3.12/site-packages/datasets/formatting/formatting.py", line 522, in format_batch
    return self.transform(batch)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/agrosavia/cacao-hf/main.py", line 576, in preprocess_train
    train_transforms(image.convert("RGB")) for image in example_batch[args.image_column_name]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/agrosavia/anaconda3/lib/python3.12/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "/home/agrosavia/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/agrosavia/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/agrosavia/anaconda3/lib/python3.12/site-packages/torchvision/transforms/transforms.py", line 805, in forward
    return F.perspective(img, startpoints, endpoints, self.interpolation, fill)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/agrosavia/anaconda3/lib/python3.12/site-packages/torchvision/transforms/functional.py", line 741, in perspective
    coeffs = _get_perspective_coeffs(startpoints, endpoints)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/agrosavia/anaconda3/lib/python3.12/site-packages/torchvision/transforms/functional.py", line 699, in _get_perspective_coeffs
    b_matrix = torch.tensor(startpoints, dtype=torch.float64).view(8)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
